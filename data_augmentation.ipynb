{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "from os.path import isfile, join, exists\n",
    "from IPython.display import display, HTML\n",
    "import PIL\n",
    "import shutil\n",
    "import itertools\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'google.colab' in str(get_ipython()):\n",
    "  from google.colab.patches import cv2_imshow\n",
    "  imshow = cv2_imshow\n",
    "else:\n",
    "  def imshow(a):\n",
    "    \"\"\"\n",
    "    img= img.clip(0, 255).astype('uint8')\n",
    "    plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "    plt.axis('off')\n",
    "    \"\"\"\n",
    "    a = a.clip(0, 255).astype('uint8')\n",
    "    if a.ndim == 3:\n",
    "      if a.shape[2] == 4:\n",
    "        a = cv2.cvtColor(a, cv2.COLOR_BGRA2RGBA)\n",
    "      else:\n",
    "        a = cv2.cvtColor(a, cv2.COLOR_BGR2RGB)\n",
    "    display(PIL.Image.fromarray(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment_img(img: np.array) -> list[np.array]:\n",
    "    img_hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV).astype(np.int16)\n",
    "    light_changes = [1 + (change * 0.06) for change in range(-10, 6, 5)]\n",
    "    blur_sigma = [0.0, 0.5, 1]\n",
    "\n",
    "    new_images = []\n",
    "    for (light, sigma) in itertools.product(light_changes, blur_sigma):\n",
    "        if light_changes == 1 and blur_sigma == 0:\n",
    "            continue\n",
    "        new_img = img_hsv.copy()\n",
    "        new_img[..., 2] = new_img[..., 2] * light\n",
    "        new_img = np.clip(new_img, 0, 255).astype(np.uint8)\n",
    "        new_img = cv2.cvtColor(new_img, cv2.COLOR_HSV2BGR)\n",
    "        if sigma > 0.0:\n",
    "            new_img = cv2.GaussianBlur(new_img, (9, 9), sigma)\n",
    "        new_images.append(new_img)\n",
    "\n",
    "    return new_images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_path = \"dataset/original\"\n",
    "augmented_path = \"dataset/augmented\"\n",
    "column_names = ['run_no', 'step_no', 'augment_idx', 'forward', 'forward_next', 'left', 'left_next']\n",
    "new_csv = []\n",
    "catalog_counter = 1\n",
    "\n",
    "if exists(augmented_path):\n",
    "    shutil.rmtree(augmented_path)\n",
    "os.mkdir(augmented_path)\n",
    "\n",
    "for loc_name in os.listdir(original_path):\n",
    "    if isfile(join(original_path, loc_name)):\n",
    "        continue\n",
    "    folder_path = join(original_path, loc_name)\n",
    "    csv_path = folder_path + '.csv'\n",
    "\n",
    "    augmented_folder_path = join(augmented_path, '{:03d}'.format(catalog_counter))\n",
    "    os.mkdir(augmented_folder_path)\n",
    "\n",
    "    control_df = pd.read_csv(csv_path, header=None)\n",
    "    step_count = control_df[0].count()\n",
    "    for step_idx, step_no in enumerate(control_df[0]):\n",
    "        img_name = '{:04d}.jpg'.format(step_no)\n",
    "        img_path = join(folder_path, img_name)\n",
    "        img = cv2.imread(img_path)\n",
    "        origin_name = \"{:04d}_{:03d}.jpg\".format(step_idx + 1, 0)\n",
    "        origin_path = join(augmented_folder_path, origin_name)\n",
    "        cv2.imwrite(origin_path, img)\n",
    "\n",
    "        forward = control_df[1][step_idx]\n",
    "        forward_next = control_df[1][step_idx + 1] if step_idx < step_count - 1 else forward\n",
    "        left = control_df[2][step_idx]\n",
    "        left_next = control_df[2][step_idx + 1] if step_idx < step_count - 1 else left\n",
    "\n",
    "        new_csv.append([catalog_counter, step_idx + 1, 0, forward, forward_next, left, left_next])\n",
    "\n",
    "        augmented_list = augment_img(img)\n",
    "        for aug_idx, aug_img in enumerate(augmented_list):\n",
    "            aug_name = \"{:04d}_{:03d}.jpg\".format(step_idx + 1, aug_idx + 1)\n",
    "            aug_path = join(augmented_folder_path, aug_name)\n",
    "            cv2.imwrite(aug_path, aug_img)\n",
    "\n",
    "            new_csv.append([catalog_counter, step_idx + 1, aug_idx + 1, forward, forward_next, left, left_next])\n",
    "        \n",
    "    catalog_counter += 1\n",
    "    \n",
    "new_control_df = pd.DataFrame(new_csv, columns=column_names)\n",
    "new_control_df.to_csv(join(augmented_path, 'control.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train/test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.default_rng(42)\n",
    "runs = new_control_df['run_no'].unique()\n",
    "test_run = rng.choice(runs)\n",
    "\n",
    "train_test = []\n",
    "for run_no in runs:\n",
    "    if run_no == test_run:\n",
    "        train_test.append([run_no, 'test'])\n",
    "    else:\n",
    "        train_test.append([run_no, 'train'])\n",
    "\n",
    "train_test_df = pd.DataFrame(train_test, columns=['run_no', 'split'])\n",
    "train_test_df.to_csv(join(augmented_path, 'train_test.csv'))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4d23b1cc31408ba59c72afb03ce07d8c08db8e1ae7bdb80d27747a1bfbd8e34d"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
