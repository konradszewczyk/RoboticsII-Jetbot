{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "from enum import Enum, auto\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import PIL\n",
    "import torch\n",
    "import torchvision.models as models\n",
    "from IPython import get_ipython\n",
    "from IPython.display import display\n",
    "from torch import nn, optim\n",
    "from torch.nn.functional import mse_loss\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from src.dataset import JetBotDataset\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "torch.backends.cudnn.benchmark = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"google.colab\" in str(get_ipython()):\n",
    "    from google.colab.patches import cv2_imshow\n",
    "\n",
    "    imshow = cv2_imshow\n",
    "else:\n",
    "\n",
    "    def imshow(a):\n",
    "        \"\"\"\n",
    "        img= img.clip(0, 255).astype('uint8')\n",
    "        plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "        plt.axis('off')\n",
    "        \"\"\"\n",
    "        a = a.clip(0, 255).astype(\"uint8\")\n",
    "        if a.ndim == 3:\n",
    "            if a.shape[2] == 4:\n",
    "                a = cv2.cvtColor(a, cv2.COLOR_BGRA2RGBA)\n",
    "            else:\n",
    "                a = cv2.cvtColor(a, cv2.COLOR_BGR2RGB)\n",
    "        display(PIL.Image.fromarray(a))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = JetBotDataset(\"dataset/augmented\", use_next=True)\n",
    "test_dataset = JetBotDataset(\"dataset/augmented\", split_type=\"test\", use_next=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=2)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=32, shuffle=True, num_workers=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(\n",
    "    model: nn.Module,\n",
    "    train_dataloader: DataLoader,\n",
    "    test_dataloader: DataLoader,\n",
    "    optimizer: optim.Optimizer,\n",
    "    no_epochs: int,\n",
    "    model_save_dir: str,\n",
    "    save_archive: bool = False,\n",
    "):\n",
    "    best_loss = np.inf\n",
    "\n",
    "    # creating unique timestamp for the run\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "    model_root_path = Path(model_save_dir)\n",
    "    model_root_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    model_best_path = model_root_path / timestamp / \"best\"\n",
    "    model_best_path.mkdir(parents=True, exist_ok=True)\n",
    "    model_best_primitive_log_path = model_best_path / \"primitive_log.txt\"\n",
    "\n",
    "    model_archive_path = model_root_path / timestamp / \"archive\"\n",
    "    model_archive_path.mkdir(parents=True, exist_ok=True)\n",
    "    model_archive_primitive_log_path = model_archive_path / \"primitive_log.txt\"\n",
    "\n",
    "    fp_best_primitive_log = open(model_best_primitive_log_path, \"w\")\n",
    "    fp_archive_primitive_log = open(model_archive_primitive_log_path, \"w\")\n",
    "\n",
    "    with open(model_archive_primitive_log_path, \"w\") as fp_archive_primitive_log:\n",
    "\n",
    "        for epoch in tqdm(range(no_epochs)):\n",
    "\n",
    "            model.train()\n",
    "            train_loss = 0.0\n",
    "            for images, labels in iter(train_dataloader):\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "                optimizer.zero_grad()\n",
    "                outputs = model(images)\n",
    "                loss = mse_loss(outputs, labels)\n",
    "                train_loss += loss\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "            train_loss /= len(train_dataloader)\n",
    "\n",
    "            model.eval()\n",
    "\n",
    "            test_loss = 0.0\n",
    "            for images, labels in iter(test_dataloader):\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "                outputs = model(images)\n",
    "\n",
    "                loss = mse_loss(outputs, labels)\n",
    "                test_loss += float(loss)\n",
    "            test_loss /= len(test_dataloader)\n",
    "\n",
    "            print(f\"Epoch: {epoch} | Train loss: {train_loss} | Test loss: {test_loss}\")\n",
    "\n",
    "            if save_archive:\n",
    "                epoch_save = f\"epoch-{epoch}.pt\"\n",
    "                torch.save(model.state_dict(), model_archive_path / epoch_save)\n",
    "                fp_archive_primitive_log.write(\n",
    "                    f\"Epoch: {epoch} | Train loss: {train_loss} | Test loss: {test_loss} \\n\"\n",
    "                )\n",
    "\n",
    "            if test_loss < best_loss:\n",
    "                best_save = \"best.pt\"\n",
    "                torch.save(model.state_dict(), model_best_path / best_save)\n",
    "\n",
    "                with open(model_best_primitive_log_path, \"w\") as fp_best_primitive_log:\n",
    "                    fp_best_primitive_log.write(\n",
    "                        f\"Epoch: {epoch} | Train loss: {train_loss} | Test loss: {test_loss}\"\n",
    "                    )\n",
    "                best_loss = test_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Models(Enum):\n",
    "    SQUEEZENET_1_1 = auto()\n",
    "    MOBILENETV3_SMALL = auto()\n",
    "    MOBILENETV3_LARGE = auto()\n",
    "    RESNET_18 = auto()\n",
    "\n",
    "\n",
    "# choose what to learn\n",
    "run_models = [Models.SQUEEZENET_1_1, Models.MOBILENETV3_SMALL]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SqueezeNet_1.1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9257bf41d73a452db11584ca24a4a18f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 | Train loss: 0.20041827857494354 | Test loss: 0.11037209095514339\n",
      "Epoch: 1 | Train loss: 0.15903347730636597 | Test loss: 0.11999999828960585\n",
      "Epoch: 2 | Train loss: 0.1511111855506897 | Test loss: 0.10952231188750138\n",
      "Epoch: 3 | Train loss: 0.14466983079910278 | Test loss: 0.1167365063143813\n",
      "Epoch: 4 | Train loss: 0.13906697928905487 | Test loss: 0.1220374249893686\n",
      "Epoch: 5 | Train loss: 0.1350688636302948 | Test loss: 0.11807350514699584\n",
      "Epoch: 6 | Train loss: 0.13204923272132874 | Test loss: 0.13024793953999228\n",
      "Epoch: 7 | Train loss: 0.12985582649707794 | Test loss: 0.12180828027751135\n",
      "Epoch: 8 | Train loss: 0.12908801436424255 | Test loss: 0.11649295938727648\n",
      "Epoch: 9 | Train loss: 0.1288008689880371 | Test loss: 0.1306081786751747\n"
     ]
    }
   ],
   "source": [
    "if Models.SQUEEZENET_1_1 in run_models:\n",
    "    squeezenet1_1 = models.squeezenet1_1(pretrained=True)\n",
    "    squeezenet1_1.classifier[1] = nn.Conv2d(512, 2, kernel_size=(1, 1), stride=(1, 1))\n",
    "    squeezenet1_1.num_classes = 2\n",
    "\n",
    "    squeezenet1_1 = squeezenet1_1.to(device)\n",
    "\n",
    "    squeezenet1_1_optimizer = optim.Adam(squeezenet1_1.parameters())\n",
    "\n",
    "    train(\n",
    "        squeezenet1_1,\n",
    "        train_dataloader,\n",
    "        test_dataloader,\n",
    "        squeezenet1_1_optimizer,\n",
    "        10,\n",
    "        \"models/SqueezeNet1_1\",\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MobileNetV3_small\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f555d54b7964418eb229075f95203843",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 | Train loss: 0.06602617353200912 | Test loss: 0.14281956462756448\n",
      "Epoch: 1 | Train loss: 0.029850967228412628 | Test loss: 0.11480542466692302\n",
      "Epoch: 2 | Train loss: 0.01799316145479679 | Test loss: 0.1213773884203123\n",
      "Epoch: 3 | Train loss: 0.01392361056059599 | Test loss: 0.1093647695429947\n",
      "Epoch: 4 | Train loss: 0.01171116717159748 | Test loss: 0.11567393269227899\n",
      "Epoch: 5 | Train loss: 0.01003354787826538 | Test loss: 0.12134120406825906\n",
      "Epoch: 6 | Train loss: 0.008867496624588966 | Test loss: 0.12490960955619812\n",
      "Epoch: 7 | Train loss: 0.007495146244764328 | Test loss: 0.1344660245206045\n",
      "Epoch: 8 | Train loss: 0.007638414856046438 | Test loss: 0.12575296895659488\n",
      "Epoch: 9 | Train loss: 0.006347826682031155 | Test loss: 0.12435894313713779\n"
     ]
    }
   ],
   "source": [
    "if Models.MOBILENETV3_SMALL in run_models:\n",
    "    mobilenetv3_small = models.mobilenet_v3_small(pretrained=True)\n",
    "    mobilenetv3_small.classifier[3] = nn.Linear(\n",
    "        in_features=1024, out_features=2, bias=True\n",
    "    )\n",
    "    mobilenetv3_small.num_classes = 2\n",
    "\n",
    "    mobilenetv3_small = mobilenetv3_small.to(device)\n",
    "\n",
    "    mobilenetv3_small_optimizer = optim.Adam(mobilenetv3_small.parameters())\n",
    "\n",
    "    train(\n",
    "        mobilenetv3_small,\n",
    "        train_dataloader,\n",
    "        test_dataloader,\n",
    "        mobilenetv3_small_optimizer,\n",
    "        no_epochs=10,\n",
    "        model_save_dir=\"models/MobileNetV3_small\",\n",
    "        save_archive=False,\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MobileNetV3_large\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "if Models.MOBILENETV3_LARGE in run_models:\n",
    "    mobilenetv3_large = models.mobilenet_v3_large(pretrained=True)\n",
    "    mobilenetv3_large.classifier[3] = nn.Linear(\n",
    "        in_features=1280, out_features=2, bias=True\n",
    "    )\n",
    "    mobilenetv3_large = mobilenetv3_large.to(device)\n",
    "    mobilenetv3_large.num_classes = 2\n",
    "\n",
    "    mobilenetv3_large_optimizer = optim.AdamW(mobilenetv3_large.parameters())\n",
    "\n",
    "    train(\n",
    "        mobilenetv3_large,\n",
    "        train_dataloader,\n",
    "        test_dataloader,\n",
    "        mobilenetv3_large_optimizer,\n",
    "        no_epochs=10,\n",
    "        model_save_dir=\"models/MobileNetV3_large\",\n",
    "        save_archive=False,\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ResNet_18\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "if Models.RESNET_18 in run_models:\n",
    "    resnet18 = models.resnet18(pretrained=True)\n",
    "    resnet18.fc = nn.Linear(in_features=512, out_features=1000, bias=True)\n",
    "    resnet18.num_classes = 2\n",
    "\n",
    "    resnet18 = resnet18.to(device)\n",
    "\n",
    "    resnet18_optimizer = optim.Adam(resnet18.parameters())\n",
    "\n",
    "    train(\n",
    "        resnet18,\n",
    "        train_dataloader,\n",
    "        test_dataloader,\n",
    "        resnet18_optimizer,\n",
    "        no_epochs=10,\n",
    "        model_save_dir=\"models/ResNet18\",\n",
    "        save_archive=False,\n",
    "    )\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d99d04fa9da62b01899aa3b88233d8d40ed3bd8f0c5ef7b3f2795f3fb70b9172"
  },
  "kernelspec": {
   "display_name": "Python 3.10.5 ('robotics')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
