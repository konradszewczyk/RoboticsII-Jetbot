{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "from enum import Enum, auto\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import PIL\n",
    "import torch\n",
    "import torchvision.models as models\n",
    "from IPython import get_ipython\n",
    "from IPython.display import display\n",
    "from torch import nn, optim\n",
    "from torch.nn.functional import mse_loss\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from src.dataset import JetBotDataset\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "torch.backends.cudnn.benchmark = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"google.colab\" in str(get_ipython()):\n",
    "    from google.colab.patches import cv2_imshow\n",
    "\n",
    "    imshow = cv2_imshow\n",
    "else:\n",
    "\n",
    "    def imshow(a):\n",
    "        \"\"\"\n",
    "        img= img.clip(0, 255).astype('uint8')\n",
    "        plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "        plt.axis('off')\n",
    "        \"\"\"\n",
    "        a = a.clip(0, 255).astype(\"uint8\")\n",
    "        if a.ndim == 3:\n",
    "            if a.shape[2] == 4:\n",
    "                a = cv2.cvtColor(a, cv2.COLOR_BGRA2RGBA)\n",
    "            else:\n",
    "                a = cv2.cvtColor(a, cv2.COLOR_BGR2RGB)\n",
    "        display(PIL.Image.fromarray(a))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = JetBotDataset(\"dataset/augmented\", use_next=True)\n",
    "test_dataset = JetBotDataset(\"dataset/augmented\", split_type=\"test\", use_next=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=2)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=32, shuffle=True, num_workers=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(\n",
    "    model: nn.Module,\n",
    "    train_dataloader: DataLoader,\n",
    "    test_dataloader: DataLoader,\n",
    "    optimizer: optim.Optimizer,\n",
    "    no_epochs: int,\n",
    "    model_save_dir: str,\n",
    "    save_archive: bool = True,\n",
    "    onnx_export: bool = True,\n",
    "):\n",
    "    best_loss = np.inf\n",
    "\n",
    "    # creating unique timestamp for the run\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "    model_root_path = Path(model_save_dir)\n",
    "    model_root_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    model_best_path = model_root_path / timestamp / \"best\"\n",
    "    model_best_path.mkdir(parents=True, exist_ok=True)\n",
    "    model_best_primitive_log_path = model_best_path / \"primitive_log.txt\"\n",
    "\n",
    "    model_archive_path = model_root_path / timestamp / \"archive\"\n",
    "    model_archive_path.mkdir(parents=True, exist_ok=True)\n",
    "    model_archive_primitive_log_path = model_archive_path / \"primitive_log.txt\"\n",
    "\n",
    "    fp_best_primitive_log = open(model_best_primitive_log_path, \"w\")\n",
    "    fp_archive_primitive_log = open(model_archive_primitive_log_path, \"w\")\n",
    "\n",
    "    with open(model_archive_primitive_log_path, \"w\") as fp_archive_primitive_log:\n",
    "\n",
    "        for epoch in tqdm(range(no_epochs)):\n",
    "\n",
    "            model.train()\n",
    "            train_loss = 0.0\n",
    "            for images, labels in iter(train_dataloader):\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "                optimizer.zero_grad()\n",
    "                outputs = model(images)\n",
    "                loss = mse_loss(outputs, labels)\n",
    "                train_loss += loss\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "            train_loss /= len(train_dataloader)\n",
    "\n",
    "            model.eval()\n",
    "\n",
    "            test_loss = 0.0\n",
    "            for images, labels in iter(test_dataloader):\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "                outputs = model(images)\n",
    "\n",
    "                loss = mse_loss(outputs, labels)\n",
    "                test_loss += float(loss)\n",
    "            test_loss /= len(test_dataloader)\n",
    "\n",
    "            print(f\"Epoch: {epoch} | Train loss: {train_loss} | Test loss: {test_loss}\")\n",
    "\n",
    "            if save_archive:\n",
    "                epoch_save = f\"epoch-{epoch}.pt\"\n",
    "                torch.save(model.state_dict(), model_archive_path / epoch_save)\n",
    "                fp_archive_primitive_log.write(\n",
    "                    f\"Epoch: {epoch} | Train loss: {train_loss} | Test loss: {test_loss} \\n\"\n",
    "                )\n",
    "\n",
    "            if test_loss < best_loss:\n",
    "                best_save = \"best.pt\"\n",
    "                torch.save(model.state_dict(), model_best_path / best_save)\n",
    "\n",
    "                with open(model_best_primitive_log_path, \"w\") as fp_best_primitive_log:\n",
    "                    fp_best_primitive_log.write(\n",
    "                        f\"Epoch: {epoch} | Train loss: {train_loss} | Test loss: {test_loss}\"\n",
    "                    )\n",
    "                best_loss = test_loss\n",
    "\n",
    "    if onnx_export:\n",
    "        model.eval()\n",
    "\n",
    "        images, labels = next(iter(train_dataloader))\n",
    "\n",
    "        dummy_input = torch.randn(\n",
    "            (1, *images[0].shape), requires_grad=True, device=device\n",
    "        )\n",
    "\n",
    "        torch.onnx.export(\n",
    "            model,\n",
    "            dummy_input,\n",
    "            model_best_path / \"best.onnx\",\n",
    "            export_params=True,\n",
    "            do_constant_folding=True,\n",
    "            input_names=[\"input\"],\n",
    "            output_names=[\"output\"],\n",
    "            dynamic_axes={\n",
    "                \"input\": {0: \"batch_size\"},\n",
    "                \"output\": {0: \"batch_size\"},\n",
    "            },\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Models(Enum):\n",
    "    SQUEEZENET_1_1 = auto()\n",
    "    MOBILENETV3_SMALL = auto()\n",
    "    MOBILENETV3_LARGE = auto()\n",
    "    RESNET_18 = auto()\n",
    "\n",
    "\n",
    "# choose what to learn\n",
    "run_models = [Models.SQUEEZENET_1_1, Models.MOBILENETV3_LARGE]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SqueezeNet_1.1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6672ffea332d418cb8574fa40084f6bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 | Train loss: 0.23616522550582886 | Test loss: 0.18023211055475732\n",
      "Epoch: 1 | Train loss: 0.2277558296918869 | Test loss: 0.18246150859024213\n",
      "Epoch: 2 | Train loss: 0.2176050990819931 | Test loss: 0.1250099338915037\n",
      "Epoch: 3 | Train loss: 0.1518300324678421 | Test loss: 0.11458147916456927\n",
      "Epoch: 4 | Train loss: 0.14124061167240143 | Test loss: 0.12155199277660121\n",
      "Epoch: 5 | Train loss: 0.13468778133392334 | Test loss: 0.12326065645269725\n",
      "Epoch: 6 | Train loss: 0.13030306994915009 | Test loss: 0.1220838307686474\n",
      "Epoch: 7 | Train loss: 0.12870106101036072 | Test loss: 0.11361809819936752\n",
      "Epoch: 8 | Train loss: 0.12772971391677856 | Test loss: 0.12516875694627347\n",
      "Epoch: 9 | Train loss: 0.12725935876369476 | Test loss: 0.12255606136244276\n"
     ]
    }
   ],
   "source": [
    "if Models.SQUEEZENET_1_1 in run_models:\n",
    "    squeezenet1_1 = models.squeezenet1_1(pretrained=True)\n",
    "    squeezenet1_1.classifier[1] = nn.Conv2d(512, 2, kernel_size=(1, 1), stride=(1, 1))\n",
    "    squeezenet1_1.num_classes = 2\n",
    "\n",
    "    squeezenet1_1 = squeezenet1_1.to(device)\n",
    "\n",
    "    squeezenet1_1_optimizer = optim.Adam(squeezenet1_1.parameters())\n",
    "\n",
    "    train(\n",
    "        squeezenet1_1,\n",
    "        train_dataloader,\n",
    "        test_dataloader,\n",
    "        squeezenet1_1_optimizer,\n",
    "        10,\n",
    "        \"models/SqueezeNet1_1\",\n",
    "        save_archive=False,\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MobileNetV3_small\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "if Models.MOBILENETV3_SMALL in run_models:\n",
    "    mobilenetv3_small = models.mobilenet_v3_small(pretrained=True)\n",
    "    mobilenetv3_small.classifier[3] = nn.Linear(\n",
    "        in_features=1024, out_features=2, bias=True\n",
    "    )\n",
    "    mobilenetv3_small.num_classes = 2\n",
    "\n",
    "    mobilenetv3_small = mobilenetv3_small.to(device)\n",
    "\n",
    "    mobilenetv3_small_optimizer = optim.Adam(mobilenetv3_small.parameters())\n",
    "\n",
    "    train(\n",
    "        mobilenetv3_small,\n",
    "        train_dataloader,\n",
    "        test_dataloader,\n",
    "        mobilenetv3_small_optimizer,\n",
    "        no_epochs=10,\n",
    "        model_save_dir=\"models/MobileNetV3_small\",\n",
    "        save_archive=False,\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MobileNetV3_large\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f70836dadfed48768d70303c84c48bf1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 | Train loss: 0.06746247410774231 | Test loss: 0.10737984433122304\n",
      "Epoch: 1 | Train loss: 0.030440136790275574 | Test loss: 0.11999593415985936\n",
      "Epoch: 2 | Train loss: 0.01984444633126259 | Test loss: 0.11515102859424509\n",
      "Epoch: 3 | Train loss: 0.01582351326942444 | Test loss: 0.11575635737213104\n",
      "Epoch: 4 | Train loss: 0.012842316180467606 | Test loss: 0.13548323674046475\n",
      "Epoch: 5 | Train loss: 0.012317637912929058 | Test loss: 0.11731053532465645\n",
      "Epoch: 6 | Train loss: 0.010483096353709698 | Test loss: 0.11745443397566029\n",
      "Epoch: 7 | Train loss: 0.009153494611382484 | Test loss: 0.12934334640917572\n",
      "Epoch: 8 | Train loss: 0.009514100849628448 | Test loss: 0.1286903998774031\n",
      "Epoch: 9 | Train loss: 0.008296911604702473 | Test loss: 0.117297045805532\n"
     ]
    }
   ],
   "source": [
    "if Models.MOBILENETV3_LARGE in run_models:\n",
    "    mobilenetv3_large = models.mobilenet_v3_large(pretrained=True)\n",
    "    mobilenetv3_large.classifier[3] = nn.Linear(\n",
    "        in_features=1280, out_features=2, bias=True\n",
    "    )\n",
    "    mobilenetv3_large = mobilenetv3_large.to(device)\n",
    "    mobilenetv3_large.num_classes = 2\n",
    "\n",
    "    mobilenetv3_large_optimizer = optim.AdamW(mobilenetv3_large.parameters())\n",
    "\n",
    "    train(\n",
    "        mobilenetv3_large,\n",
    "        train_dataloader,\n",
    "        test_dataloader,\n",
    "        mobilenetv3_large_optimizer,\n",
    "        no_epochs=10,\n",
    "        model_save_dir=\"models/MobileNetV3_large\",\n",
    "        save_archive=False,\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ResNet_18\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "if Models.RESNET_18 in run_models:\n",
    "    resnet18 = models.resnet18(pretrained=True)\n",
    "    resnet18.fc = nn.Linear(in_features=512, out_features=1000, bias=True)\n",
    "    resnet18.num_classes = 2\n",
    "\n",
    "    resnet18 = resnet18.to(device)\n",
    "\n",
    "    resnet18_optimizer = optim.Adam(resnet18.parameters())\n",
    "\n",
    "    train(\n",
    "        resnet18,\n",
    "        train_dataloader,\n",
    "        test_dataloader,\n",
    "        resnet18_optimizer,\n",
    "        no_epochs=10,\n",
    "        model_save_dir=\"models/ResNet18\",\n",
    "        save_archive=False,\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d99d04fa9da62b01899aa3b88233d8d40ed3bd8f0c5ef7b3f2795f3fb70b9172"
  },
  "kernelspec": {
   "display_name": "Python 3.10.5 ('robotics')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
